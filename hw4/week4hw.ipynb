{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "input_data_path = 'lectures/week1/big_data_intro.txt'\n",
    "text_file = sc.textFile(input_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_length_pair_rdd = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    ".map(lambda word: (word, random.random()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Introduction', 0.9978105188713383), ('Big', 0.7288432707952055), ('data', 0.6033462691888698), ('is', 0.3007339683233068), ('a', 0.8021923560874618), ('blanket', 0.7462439936487744), ('term', 0.017247876022995157), ('for', 0.826548776562138), ('the', 0.4891730263516276), ('non-traditional', 0.24088049437029413)]\n"
     ]
    }
   ],
   "source": [
    "print(word_to_length_pair_rdd.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction', 'Big', 'data', 'is', 'a', 'blanket', 'term', 'for', 'the', 'non-traditional']\n",
      "key = Introduction\n",
      "key = Big\n",
      "key = data\n",
      "key = is\n",
      "key = a\n",
      "key = blanket\n",
      "key = term\n",
      "key = for\n",
      "key = the\n",
      "key = non-traditional\n",
      "0.24088049437029413\n",
      "[('Introduction', 1), ('Big', 12), ('data', 126), ('is', 59), ('a', 66), ('blanket', 1), ('term', 7), ('for', 42), ('the', 145), ('non-traditional', 1)]\n",
      "[('', 186), ('The', 149), ('Tragedy', 1), ('of', 623), ('Hamlet,', 23), ('Prince', 1), ('Denmark', 9), ('Shakespeare', 1), ('homepage', 1), ('|', 2)]\n",
      "[('is', (59, 291)), ('a', (66, 450)), ('term', (7, 2)), ('for', (42, 164)), ('the', (145, 988)), ('and', (103, 693)), ('to', (87, 604)), ('gather', (2, 1)), ('process', (15, 1)), ('from', (18, 83)), ('large', (18, 1)), ('While', (9, 1)), ('of', (111, 623)), ('working', (4, 1)), ('with', (26, 220)), ('that', (32, 228)), ('power', (1, 7)), ('or', (19, 78)), ('single', (7, 2)), ('not', (6, 259)), ('new', (4, 2)), ('scale', (5, 2)), ('this', (13, 204)), ('has', (4, 15)), ('greatly', (1, 1)), ('in', (41, 387)), ('years', (1, 1)), ('', (38, 186)), ('In', (6, 36)), ('article', (1, 1)), ('we', (7, 107)), ('will', (5, 133)), ('talk', (4, 2)), ('about', (6, 13)), ('on', (18, 100)), ('level', (3, 1)), ('define', (3, 1)), ('common', (4, 5)), ('you', (2, 356)), ('might', (5, 28)), ('come', (1, 47)), ('while', (2, 6)), ('subject', (1, 2)), ('We', (1, 29)), ('also', (7, 1)), ('take', (3, 26)), ('look', (2, 16)), ('at', (8, 75)), ('some', (6, 52)), ('being', (6, 8)), ('used', (13, 1)), ('What', (2, 77)), ('Is', (1, 27)), ('An', (1, 7)), ('exact', (1, 1)), ('down', (2, 11)), ('because', (4, 1)), ('business', (2, 8)), ('use', (2, 14)), ('it', (14, 270)), ('quite', (2, 3)), ('With', (2, 43)), ('mind', (2, 7)), ('are', (35, 119)), ('means', (5, 14)), ('too', (1, 33)), ('This', (16, 45)), ('may', (2, 58)), ('Why', (1, 21)), ('Are', (1, 8)), ('The', (18, 149)), ('same', (3, 10)), ('as', (17, 146)), ('any', (3, 17)), ('speed', (3, 3)), ('must', (1, 53)), ('be', (28, 192)), ('dealt', (1, 1)), ('each', (6, 8)), ('stage', (2, 2)), ('present', (2, 3)), ('when', (5, 28)), ('most', (7, 70)), ('would', (2, 63)), ('possible', (2, 1)), ('first', (1, 12)), ('what', (3, 110)), ('became', (1, 1)), ('known', (2, 5)), ('three', (3, 9)), ('make', (5, 45)), ('different', (6, 1)), ('other', (9, 11)), ('helps', (1, 1)), ('These', (5, 7)), ('can', (33, 32)), ('larger', (1, 1)), ('than', (3, 38)), ('which', (11, 35)), ('demands', (2, 1)), ('more', (11, 69)), ('thought', (1, 6)), ('life', (2, 12)), ('work', (9, 5)), ('exceed', (1, 1)), ('becomes', (3, 2)), ('capable', (1, 1)), ('breaking', (2, 1)), ('into', (11, 26)), ('important', (5, 1)), ('Another', (5, 6)), ('way', (4, 7)), ('moves', (1, 2)), ('through', (4, 8)), ('often', (11, 2)), ('time', (4, 27)), ('gain', (2, 2)), ('understanding', (1, 2)), ('near', (2, 6)), ('instant', (1, 4)), ('driven', (1, 1)), ('many', (5, 17)), ('away', (1, 8)), ('order', (1, 2)), ('keep', (1, 16)), ('up', (4, 26)), ('guard', (1, 1)), ('against', (1, 18)), ('along', (1, 2)), ('wide', (3, 2)), ('both', (2, 17)), ('their', (5, 54)), ('relative', (1, 1)), ('quality', (6, 3)), ('like', (14, 68)), ('seeks', (1, 1)), ('where', (1, 28)), ('its', (3, 2)), ('coming', (1, 4)), ('by', (13, 96)), ('all', (4, 88)), ('well', (1, 27)), ('Rich', (1, 1)), ('enter', (1, 3)), ('already', (2, 2)), ('raw', (8, 1)), ('state', (3, 6)), ('changes', (4, 1)), ('memory', (5, 7)), ('have', (4, 158)), ('though', (1, 16)), ('these', (7, 38)), ('rather', (1, 3)), ('Some', (1, 2)), ('lead', (1, 4)), ('leads', (1, 1)), ('low', (1, 1)), ('place', (4, 4)), ('enough', (1, 4)), ('Does', (1, 3)), ('Look', (1, 9)), ('So', (1, 38)), ('how', (3, 31)), ('there', (2, 41)), ('below', (1, 2)), ('true', (1, 14)), ('they', (4, 78)), ('general', (2, 6)), ('Before', (1, 4)), ('four', (1, 4)), ('moment', (1, 2)), ('an', (6, 49)), ('To', (2, 124)), ('better', (2, 11)), ('address', (1, 1)), ('high', (3, 2)), ('needs', (1, 7)), ('fit', (2, 7)), ('hold', (1, 21)), ('clear', (1, 1)), ('benefit', (1, 1)), ('but', (4, 148)), ('High', (1, 1)), ('fault', (2, 4)), ('prevent', (1, 1)), ('access', (2, 1)), ('easy', (1, 1)), ('without', (1, 13)), ('machine', (3, 1)), ('stands', (3, 5)), ('Yet', (1, 10)), ('depends', (1, 1)), ('heavily', (1, 1)), ('far', (1, 10)), ('One', (3, 5)), ('between', (2, 13)), ('help', (1, 4)), ('end', (1, 9)), ('takes', (1, 6)), ('sometimes', (2, 4)), ('called', (5, 1)), ('transform', (2, 1)), ('load', (2, 1)), ('out', (1, 37)), ('bad', (1, 4)), ('certain', (3, 3)), ('those', (1, 20)), ('should', (1, 53)), ('kept', (1, 4)), ('further', (1, 9)), ('hand', (1, 13)), ('off', (1, 14)), ('so', (1, 103)), ('seems', (1, 4)), ('simple', (1, 1)), ('volume', (2, 1)), ('necessary', (1, 2)), ('There', (2, 11)), ('choose', (1, 4)), ('want', (1, 2)), ('purpose', (1, 4)), ('best', (4, 9)), ('serve', (1, 2)), ('read', (1, 1)), ('our', (1, 106)), ('Once', (1, 2)), ('begin', (1, 1)), ('perhaps', (1, 3)), ('part', (1, 20)), ('either', (1, 6)), ('one', (2, 28)), ('method', (1, 1)), ('over', (6, 2)), ('piece', (1, 4)), ('then', (2, 18)), ('very', (2, 56)), ('good', (1, 73)), ('made', (1, 26)), ('composed', (2, 1)), ('avoid', (1, 2)), ('having', (1, 1)), ('write', (1, 1)), ('back', (1, 6)), ('ways', (3, 1)), ('above', (2, 2)), ('within', (2, 17)), ('For', (3, 64)), ('instance', (1, 1)), ('straight', (1, 1)), ('themselves', (1, 4)), ('sense', (1, 7)), ('points', (1, 1)), ('health', (1, 5)), ('A', (1, 77)), ('them', (3, 42)), ('helpful', (1, 1)), ('cannot', (1, 23)), ('due', (2, 1)), ('sets', (4, 2)), ('started', (1, 1)), ('complete', (1, 1)), ('spirit', (1, 8)), ('mining', (2, 1)), ('broad', (3, 2)), ('find', (2, 17)), ('It', (3, 55)), ('mass', (1, 1)), ('set', (3, 20)), ('been', (1, 25)), ('spoken', (1, 1)), ('found', (1, 4)), ('project', (1, 1)), ('was', (1, 67)), ('top', (1, 6)), ('provided', (1, 1)), ('run', (1, 1)), ('moving', (1, 1)), ('held', (1, 2)), ('gives', (1, 5)), ('huge', (1, 1)), ('bound', (1, 3)), ('study', (1, 1)), ('fed', (2, 2)), ('behavior', (1, 1)), ('model', (1, 1)), ('move', (1, 5)), ('By', (1, 18)), ('deal', (1, 1))]\n"
     ]
    }
   ],
   "source": [
    "word_to_length_pair_keys_rdd = word_to_length_pair_rdd.keys()\n",
    "\n",
    "print(word_to_length_pair_keys_rdd.take(10))\n",
    "\n",
    " \n",
    "\n",
    "word_to_length_pair_group_rdd = word_to_length_pair_rdd.groupByKey()\n",
    "\n",
    "group_result = word_to_length_pair_group_rdd.take(10)\n",
    "for key, values in group_result:\n",
    "    print('key = {}'.format(key))\n",
    "for value in values:\n",
    "    print(value)\n",
    "\n",
    " \n",
    "\n",
    "bigdata_word_to_count_pair_rdd = sc.textFile('lectures/week1/big_data_intro.txt') \\\n",
    ".flatMap(lambda line: line.split(\" \")) \\\n",
    ".map(lambda word: (word, 1)) \\\n",
    ".reduceByKey(lambda a, b: a + b)\n",
    "#bigdata_word_to_count_pair_rdd = bigdata_word_to_count_pair_rdd.repartition(len(bigdata_word_to_count_pair_rdd.collect()))\n",
    "\n",
    "print(bigdata_word_to_count_pair_rdd.take(10))\n",
    "\n",
    "hamlet_word_to_count_pair_rdd = sc.textFile('lectures/week4/hamlet.txt') \\\n",
    ".flatMap(lambda line: line.split(\" \")) \\\n",
    ".map(lambda word: (word, 1)) \\\n",
    ".reduceByKey(lambda a, b: a + b)\n",
    "#hamlet_word_to_count_pair_rdd = hamlet_word_to_count_pair_rdd.repartition(len(hamlet_word_to_count_pair_rdd.collect()))\n",
    "\n",
    "print(hamlet_word_to_count_pair_rdd.take(10))\n",
    "\n",
    " \n",
    "\n",
    "bigdata_join_hamlet_rdd = bigdata_word_to_count_pair_rdd.join(hamlet_word_to_count_pair_rdd)\n",
    "print(bigdata_join_hamlet_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
